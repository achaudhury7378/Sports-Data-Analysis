{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark as ps\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[4]') \\\n",
    "    .appName('project#1') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "spark = ps.sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas=(sc.textFile(\"mydata.csv\") \n",
    "    .map(lambda line: line.split(\",\"))\n",
    "    .filter(lambda x: x[1] in ['RCB','SRH','MI','RPS','GL','KKR','KXIP','DD'] )  \n",
    "    .map(lambda x:(x[2],int(x[4])))\n",
    "    .groupByKey()\n",
    "    .map(lambda x:(x[0],np.max(list(x[1])),np.min(list(x[1])),np.quantile(list(x[1]),0.25),np.quantile(list(x[1]),0.5),np.quantile(list(x[1]),0.75)))\n",
    "    .collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df=pd.DataFrame(datas,columns=['Player','Max_Score','Min_score','Frst_quantile','Median','Last_quantile'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my_df caculates performance of all player in every team  as asked in Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Max_Score</th>\n",
       "      <th>Min_score</th>\n",
       "      <th>Frst_quantile</th>\n",
       "      <th>Median</th>\n",
       "      <th>Last_quantile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CH Gayle</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sachin Baby</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TS Mills</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DJ Hooda</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>9.75</td>\n",
       "      <td>12.5</td>\n",
       "      <td>15.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yuvraj Singh</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>9.0</td>\n",
       "      <td>36.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Player  Max_Score  Min_score  Frst_quantile  Median  Last_quantile\n",
       "0      CH Gayle         77          0           6.00     8.0          32.00\n",
       "1   Sachin Baby         12          1           1.50     2.0           7.00\n",
       "2      TS Mills          6          0           1.00     2.0           4.00\n",
       "3      DJ Hooda         19          9           9.75    12.5          15.25\n",
       "4  Yuvraj Singh         70          0           5.50     9.0          36.50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn(A):\n",
    "    k=A[0]\n",
    "    B=A[1]\n",
    "    cluster=[]\n",
    "    for i in range(0,len(B),3):\n",
    "        cluster.append(B[i:i+3])\n",
    "    teams=cluster[0][0:2]\n",
    "    team_1=filter(lambda x:x[0]==teams[0],cluster)\n",
    "    team_2=filter(lambda x:x[0]==teams[1],cluster)\n",
    "    s=0\n",
    "    for c in team_1:\n",
    "        s=s+c[2]\n",
    "    u=0\n",
    "    for c in team_2:\n",
    "        u=u+c[2]\n",
    "    p=1\n",
    "    w=0\n",
    "    if s>u:\n",
    "        w=1\n",
    "    return k,teams[0],teams[1],s,u,p,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(A):\n",
    "    team_1=A[2]\n",
    "    team_2=A[1]\n",
    "    s=A[4]\n",
    "    u=A[3]\n",
    "    p=1\n",
    "    w=0\n",
    "    if s>u:\n",
    "        w=1\n",
    "    return (A[0],team_1,team_2,s,u,p,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2(A):\n",
    "    k=A[0]\n",
    "    B=A[1]\n",
    "    cluster=[]\n",
    "    dict_1={}\n",
    "    for i in range(0,len(B),2):\n",
    "        cluster.append(B[i:i+2])\n",
    "    for i in cluster:\n",
    "        if i[0] in dict_1.keys():\n",
    "            dict_1[i[0]]=dict_1[i[0]]+i[1]\n",
    "        else:\n",
    "            dict_1[i[0]]=i[1]\n",
    "    values=[]\n",
    "    for i in dict_1.keys():\n",
    "        values.append(2*dict_1[i])\n",
    "    return (k,values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "data2=(sc.textFile(\"mydata.csv\") \n",
    "    .map(lambda line: line.split(\",\"))\n",
    "    .filter(lambda x: x[1] in ['RCB','SRH','MI','RPS','GL','KKR','KXIP','DD'] )\n",
    "    .map(lambda x:(int(x[0]),(x[1],x[3],int(x[5]))))\n",
    "    .reduceByKey(add) \n",
    "    .sortByKey()  \n",
    "    .map(fn)\n",
    "    .flatMap(lambda x:(x,f1(x)))\n",
    "    .map(lambda x:(x[1],(x[2],x[6]))) \n",
    "    .reduceByKey(add) \n",
    "    .map(f2)\n",
    "    .map(lambda x:(x[0],np.max(list(x[1])),np.min(list(x[1])),np.quantile(list(x[1]),0.25),np.quantile(list(x[1]),0.5),np.quantile(list(x[1]),0.75)))  \n",
    "    .collect())\n",
    "# print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data2,columns=['Team','Max_Score','Min_score','Frst_quantile','Median','Last_quantile'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe my_df calculates the boxplot metrics of all team overall performances based on player performances as asked in Question 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Max_Score</th>\n",
       "      <th>Min_score</th>\n",
       "      <th>Frst_quantile</th>\n",
       "      <th>Median</th>\n",
       "      <th>Last_quantile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RCB</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRH</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MI</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RPS</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KKR</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GL</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KXIP</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DD</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Team  Max_Score  Min_score  Frst_quantile  Median  Last_quantile\n",
       "0   RCB          4          0            0.0     0.0            1.0\n",
       "1   SRH          4          0            2.0     2.0            4.0\n",
       "2    MI          6          2            2.0     4.0            4.0\n",
       "3   RPS          6          0            2.0     2.0            4.0\n",
       "4   KKR          4          0            2.0     2.0            3.0\n",
       "5    GL          2          0            0.0     2.0            2.0\n",
       "6  KXIP          4          0            2.0     2.0            2.0\n",
       "7    DD          4          0            0.0     2.0            3.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f3(A):\n",
    "    k=A[0]\n",
    "    B=A[1]\n",
    "    cluster=[]\n",
    "    dict_1={}\n",
    "    for i in range(0,len(B),2):\n",
    "        cluster.append(B[i:i+2])\n",
    "    for i in cluster:\n",
    "        if i[0] in dict_1.keys():\n",
    "            dict_1[i[0]]=dict_1[i[0]]+i[1]\n",
    "        else:\n",
    "            dict_1[i[0]]=i[1]\n",
    "    values=[]\n",
    "    for i in dict_1.keys():\n",
    "        values.append((k,i,dict_1[i]))\n",
    "        \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=(sc.textFile(\"mydata.csv\") \n",
    "    .map(lambda line: line.split(\",\"))\n",
    "    .filter(lambda x: x[1] in ['RCB','SRH','MI','RPS','GL','KKR','KXIP','DD'] )\n",
    "    .map(lambda x:(int(x[0]),(x[1],x[3],int(x[5]))))\n",
    "    .reduceByKey(add) \n",
    "    .sortByKey()  \n",
    "    .map(fn)\n",
    "    .flatMap(lambda x:(x,f1(x)))\n",
    "    .map(lambda x:(x[1],(x[2],x[6]))) \n",
    "    .reduceByKey(add) \n",
    "    .flatMap(f3)\n",
    "    .collect())\n",
    "# print(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_1=(sc.textFile(\"mydata.csv\") \n",
    "    .map(lambda line: line.split(\",\"))\n",
    "    .filter(lambda x: x[1] in ['RCB','SRH','MI','RPS','GL','KKR','KXIP','DD'] )\n",
    "    .map(lambda x:(int(x[0]),(x[1],x[3],int(x[5]))))\n",
    "    .reduceByKey(add) \n",
    "    .sortByKey()  \n",
    "    .map(fn)\n",
    "    .flatMap(lambda x:(x,f1(x)))\n",
    "    .map(lambda x:(x[1],(x[2],x[5]))) \n",
    "    .reduceByKey(add) \n",
    "    .flatMap(f3)\n",
    "    .collect())\n",
    "# print(dat_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals=[]\n",
    "for i in range(len(dat)):\n",
    "    A=dat[i]\n",
    "    B=dat_1[i]\n",
    "    c=float(A[-1])/float(B[-1])\n",
    "    vals.append((A[0],A[1],c))\n",
    "# print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_like=pd.DataFrame(vals,columns=['team_1','team_2','probability_win_team_1over_team_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_like represents the probabilty  that team_1 wins over team_2 as asked in Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   team_1 team_2  probability_win_team_1over_team_2\n",
      "0     RCB    SRH                           0.000000\n",
      "1     RCB     DD                           1.000000\n",
      "2     RCB   KXIP                           0.000000\n",
      "3     RCB     MI                           0.000000\n",
      "4     RCB    RPS                           0.000000\n",
      "5     RCB     GL                           0.500000\n",
      "6     RCB    KKR                           0.000000\n",
      "7     SRH    RCB                           1.000000\n",
      "8     SRH     GL                           1.000000\n",
      "9     SRH     MI                           0.500000\n",
      "10    SRH    KKR                           0.666667\n",
      "11    SRH   KXIP                           1.000000\n",
      "12    SRH     DD                           0.500000\n",
      "13    SRH    RPS                           0.000000\n",
      "14     MI    RPS                           0.250000\n",
      "15     MI    KKR                           1.000000\n",
      "16     MI    SRH                           0.500000\n",
      "17     MI    RCB                           1.000000\n",
      "18     MI     GL                           1.000000\n",
      "19     MI   KXIP                           0.500000\n",
      "20     MI     DD                           1.000000\n",
      "21    RPS     MI                           0.750000\n",
      "22    RPS   KXIP                           0.500000\n",
      "23    RPS     DD                           0.000000\n",
      "24    RPS     GL                           0.500000\n",
      "25    RPS    RCB                           1.000000\n",
      "26    RPS    SRH                           1.000000\n",
      "27    RPS    KKR                           0.500000\n",
      "28    KKR     GL                           0.500000\n",
      "29    KKR     MI                           0.000000\n",
      "30    KKR   KXIP                           0.500000\n",
      "31    KKR    SRH                           0.333333\n",
      "32    KKR     DD                           1.000000\n",
      "33    KKR    RCB                           1.000000\n",
      "34    KKR    RPS                           0.500000\n",
      "35     GL    KKR                           0.500000\n",
      "36     GL    SRH                           0.000000\n",
      "37     GL    RPS                           0.500000\n",
      "38     GL     MI                           0.000000\n",
      "39     GL    RCB                           0.500000\n",
      "40     GL   KXIP                           0.500000\n",
      "41     GL     DD                           0.000000\n",
      "42   KXIP    RPS                           0.500000\n",
      "43   KXIP    RCB                           1.000000\n",
      "44   KXIP    KKR                           0.500000\n",
      "45   KXIP     DD                           0.500000\n",
      "46   KXIP    SRH                           0.000000\n",
      "47   KXIP     MI                           0.500000\n",
      "48   KXIP     GL                           0.500000\n",
      "49     DD    RCB                           0.000000\n",
      "50     DD    RPS                           1.000000\n",
      "51     DD   KXIP                           0.500000\n",
      "52     DD    KKR                           0.000000\n",
      "53     DD    SRH                           0.500000\n",
      "54     DD     MI                           0.000000\n",
      "55     DD     GL                           1.000000\n"
     ]
    }
   ],
   "source": [
    "print(df_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(A):\n",
    "    ranks={'RCB':8,'SRH':3,'MI':1,'RPS':2,'GL':7,'KKR':4,'KXIP':5,'DD':6}\n",
    "    return A[0],A[1],A[2],ranks[A[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "data1=(sc.textFile(\"mydata.csv\") \n",
    "    .map(lambda line: line.split(\",\"))\n",
    "    .filter(lambda x: x[1] in ['RCB','SRH','MI','RPS','GL','KKR','KXIP','DD'] )\n",
    "    .map(lambda x:(int(x[0]),(x[1],x[3],int(x[5]))))\n",
    "    .reduceByKey(add) \n",
    "    .sortByKey()  \n",
    "    .map(fn)\n",
    "    .flatMap(lambda x:(x,f1(x)))\n",
    "    .map(lambda x:(x[1],(x[2],x[5]))) \n",
    "    .reduceByKey(add) \n",
    "    .flatMap(f3)\n",
    "    .map(rank))\n",
    "df=spark.createDataFrame(data1,['Team_1','Team_2','n_mathes_played','labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+---------------+------+\n",
      "|Team_1|Team_2|n_mathes_played|labels|\n",
      "+------+------+---------------+------+\n",
      "|   RCB|   SRH|              1|     8|\n",
      "|   RCB|    DD|              2|     8|\n",
      "|   RCB|  KXIP|              2|     8|\n",
      "|   RCB|    MI|              2|     8|\n",
      "|   RCB|   RPS|              2|     8|\n",
      "|   RCB|    GL|              2|     8|\n",
      "|   RCB|   KKR|              2|     8|\n",
      "|   SRH|   RCB|              1|     3|\n",
      "|   SRH|    GL|              2|     3|\n",
      "|   SRH|    MI|              2|     3|\n",
      "+------+------+---------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=(sc.textFile(\"random.txt\") \n",
    "    .map(lambda line: line.split(\"\\t\"))\n",
    "    .map(lambda x:(x[1],x[2],int(x[3])))\n",
    "    .filter(lambda x:x[2]!=0)\n",
    "    .collect())\n",
    "df_predict_1=spark.createDataFrame(new_data,['Team_1','Team_2','n_mathes_played'])\n",
    "# print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler,OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=df.columns[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringindexer_stages = [StringIndexer(inputCol=c, outputCol='strindexed_' + c) for c in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder_stages = [OneHotEncoder(inputCol='strindexed_' + c, outputCol='onehot_' + c) for c in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['onehot_' + c for c in cat_cols]\n",
    "vectorassembler_stage = VectorAssembler(inputCols=feature_columns, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stages = stringindexer_stages + onehotencoder_stages + [vectorassembler_stage]\n",
    "pipeline = Pipeline(stages=all_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = feature_columns + ['Team_1','features', 'labels']\n",
    "new_df = pipeline_model.transform(df).\\\n",
    "            select(final_columns)\n",
    "# new_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(featuresCol='features', labelCol='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = dt.fit(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = feature_columns + ['Team_1','features']\n",
    "df_pred_1 = pipeline_model.transform(df_predict_1).\\\n",
    "            select(final_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranks of team in the new season as asked in Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|Team_1|prediction|\n",
      "+------+----------+\n",
      "|SRH   |2.0       |\n",
      "|MI    |1.0       |\n",
      "|RPS   |2.0       |\n",
      "|GL    |7.0       |\n",
      "|KKR   |4.0       |\n",
      "|KXIP  |5.0       |\n",
      "|DD    |6.0       |\n",
      "|RCB   |2.0       |\n",
      "+------+----------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_columns = ['Team_1', 'prediction']\n",
    "pred_training_cv = cv_model.transform(df_pred_1)\n",
    "pred_training_cv.select(show_columns).show(8, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def win(A):\n",
    "    w=0\n",
    "    if A[0]=='MI':\n",
    "        w=1\n",
    "    return A[0],A[1],A[2],w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=(sc.textFile(\"mydata.csv\") \n",
    "    .map(lambda line: line.split(\",\"))\n",
    "    .filter(lambda x: x[1] in ['RCB','SRH','MI','RPS','GL','KKR','KXIP','DD'] )\n",
    "    .map(lambda x:(int(x[0]),(x[1],x[3],int(x[5]))))\n",
    "    .reduceByKey(add) \n",
    "    .sortByKey()  \n",
    "    .map(fn)\n",
    "    .flatMap(lambda x:(x,f1(x)))\n",
    "    .map(lambda x:(x[1],(x[2],x[5]))) \n",
    "    .reduceByKey(add) \n",
    "    .flatMap(f3)\n",
    "    .map(win)\n",
    "   .collect())\n",
    "d1_df=spark.createDataFrame(d1,['Team_1','Team_2','n_mathes_played','labels'])\n",
    "# print(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=d1_df.columns[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringindexer_stages = [StringIndexer(inputCol=c, outputCol='strindexed_' + c) for c in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder_stages = [OneHotEncoder(inputCol='strindexed_' + c, outputCol='onehot_' + c) for c in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['onehot_' + c for c in cat_cols]\n",
    "vectorassembler_stage = VectorAssembler(inputCols=feature_columns, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stages = stringindexer_stages + onehotencoder_stages + [vectorassembler_stage]\n",
    "pipeline = Pipeline(stages=all_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model_1 = pipeline.fit(d1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = feature_columns + ['Team_1','features', 'labels']\n",
    "new_d1_df = pipeline_model_1.transform(d1_df).\\\n",
    "            select(final_columns)\n",
    "# new_d1_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "logr = LogisticRegression(featuresCol='features', labelCol='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = logr.fit(new_d1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns_1 = feature_columns + ['Team_1','features']\n",
    "df_pred_1 = pipeline_model_1.transform(df_predict_1).\\\n",
    "            select(final_columns_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred_1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+------------------------------------------+\n",
      "|Team_1|prediction|probability                               |\n",
      "+------+----------+------------------------------------------+\n",
      "|SRH   |0.0       |[0.9999999287932635,7.120673665259581E-8] |\n",
      "|MI    |1.0       |[4.436711765646851E-9,0.9999999955632881] |\n",
      "|RPS   |0.0       |[0.9999963494021604,3.6505978394815447E-6]|\n",
      "|GL    |0.0       |[0.9999999976848515,2.3151485392682334E-9]|\n",
      "|KKR   |0.0       |[0.9999669570219757,3.3042978024386555E-5]|\n",
      "|KXIP  |0.0       |[0.9999999944901519,5.509848051069725E-9] |\n",
      "|DD    |0.0       |[0.9999999976848515,2.3151485392682334E-9]|\n",
      "|RCB   |0.0       |[0.9999999820722162,1.7927783900410936E-8]|\n",
      "+------+----------+------------------------------------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_columns = ['Team_1', 'prediction','probability']\n",
    "pred_training_lr = lr_model.transform(df_pred_1)\n",
    "pred_training_lr.select(show_columns).show(8, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "de=pred_training_lr.select(show_columns).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "de['prob']=de['probability'].apply(lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "de=de.drop(['prediction','probability'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability of a team winning the new season as asked in Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Team_1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DD</th>\n",
       "      <td>3.678512e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GL</th>\n",
       "      <td>3.568309e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KKR</th>\n",
       "      <td>4.755662e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KXIP</th>\n",
       "      <td>3.310891e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MI</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RCB</th>\n",
       "      <td>5.274940e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RPS</th>\n",
       "      <td>7.357424e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRH</th>\n",
       "      <td>2.219973e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                prob\n",
       "Team_1              \n",
       "DD      3.678512e-06\n",
       "GL      3.568309e-05\n",
       "KKR     4.755662e-06\n",
       "KXIP    3.310891e-05\n",
       "MI      1.000000e+00\n",
       "RCB     5.274940e-06\n",
       "RPS     7.357424e-07\n",
       "SRH     2.219973e-04"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de.groupby('Team_1').mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
